# Biomni DeepSeek Configuration
# DeepSeek API配置 - 使用DeepSeek的强大模型

# DeepSeek使用OpenAI兼容的API
# 设置API密钥
OPENAI_API_KEY=sk-6f73c67f11d5469e846aba019b0f3530

# 设置为Custom源（因为我们需要自定义base_url）
LLM_SOURCE=Custom

# 设置DeepSeek模型名称
# DeepSeek-V3.2 模型:
#   - deepseek-chat (非思考模式，快速响应)
#   - deepseek-reasoner (思考模式，深度推理，推荐用于复杂任务)
BIOMNI_LLM=deepseek-reasoner

# 自定义模型Base URL（DeepSeek API端点）
CUSTOM_MODEL_BASE_URL=https://api.deepseek.com

# API密钥（自定义源需要）
CUSTOM_MODEL_API_KEY=sk-6f73c67f11d5469e846aba019b0f3530

# 可选: Temperature参数
# DeepSeek建议的温度范围: 0.0-2.0
# 较低的值(如0.3)产生更确定的输出，较高的值(如1.0)产生更有创意的输出
BIOMNI_TEMPERATURE=0.7

# 可选: 超时设置
# DeepSeek通常响应很快，但复杂任务可能需要更长时间
BIOMNI_TIMEOUT_SECONDS=600

# 可选: 数据路径
# BIOMNI_DATA_PATH=./data

# 注意:
# 1. DeepSeek-V3.2 完全兼容OpenAI API格式
# 2. deepseek-reasoner 使用思考模式，提供更深度的推理
# 3. Token限制: 支持64K上下文
# 4. 价格: 约 ¥1/百万tokens (输入)，非常实惠
# 5. reasoning模式会先进行内部思考，然后输出答案
#
# 官方文档: https://platform.deepseek.com/api-docs/
