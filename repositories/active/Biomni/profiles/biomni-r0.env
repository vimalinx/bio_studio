# Biomni-R0 Configuration
# This profile is configured for using Biomni-R0 model via SGLang
# while keeping database queries on Claude (recommended setup)

# Anthropic API for database queries (indexes, retrieval, etc.)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Custom model configuration for Biomni-R0 reasoning
# Make sure SGLang server is running on localhost:30000
CUSTOM_MODEL_BASE_URL=http://localhost:30000/v1
CUSTOM_MODEL_API_KEY=EMPTY

# Set source to Custom
LLM_SOURCE=Custom

# Biomni-R0 model name
BIOMNI_LLM=biomni/Biomni-R0-32B-Preview

# Optional: Temperature for generation
# BIOMNI_TEMPERATURE=0.7

# Optional: Timeout settings (may need longer timeout for local models)
# BIOMNI_TIMEOUT_SECONDS=1200

# Optional: Data path
# BIOMNI_DATA_PATH=./data

# Note: Before using this profile, you need to:
# 1. Install SGLang: pip install "sglang[all]"
# 2. Start the SGLang server with Biomni-R0:
#    python -m sglang.launch_server --model-path RyanLi0802/Biomni-R0-Preview \
#      --port 30000 --host 0.0.0.0 --mem-fraction-static 0.8 --tp 2 \
#      --trust-remote-code --json-model-override-args \
#      '{"rope_scaling":{"rope_type":"yarn","factor":1.0, \
#        "original_max_position_embeddings":32768}, \
#        "max_position_embeddings": 131072}'
# 3. Then use this profile and initialize agent like:
#    from biomni.config import default_config
#    from biomni.agent import A1
#
#    # Database queries use Anthropic
#    default_config.llm = "claude-3-5-sonnet-20241022"
#    default_config.source = "Anthropic"
#
#    # Agent reasoning uses Biomni-R0
#    agent = A1(
#        llm="biomni/Biomni-R0-32B-Preview",
#        source="Custom",
#        base_url="http://localhost:30000/v1",
#        api_key="EMPTY",
#    )
